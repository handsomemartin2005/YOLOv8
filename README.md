# YOLOv8
## 项目目标
1.收集电能表、计量设备、互感器等设备招标公告，在https://ecp.sgcc.com.cn/ 进行数据搜集并爬取下来中标公司相关信息
2.收集电能表实例图片，利用YOLOv8正确识别图片中表显区域，对区域进行OCR识别，对识别出的数字、文字文本进行LLM分析所涉及的company,model,error code
## 项目实施
### 数据搜集
收集电能表、互感器数据，利用python进行数据爬取，数据导出至DNB_result.csv,HGQ_result.csv;分别存入DNB,HGQ文件夹中，代码详见HGQ_process.py,DNB_process.py
### 图片识别
数据为.jpg格式图片(images)以7/3比例分为训练集(train)和验证集(val)，进行图片标注后利用yolov8n进行图像识别
#### 实验环境
python解释器:python 3.8
anaconda环境下配置，环境名为yolo
#### 图片标注
原始图片共260张，182张作为训练集，78张作为验证集
下载labelimg图片标注，进行手动图片标注，类别仅一种，命名为DNB；结果存放在labels文件夹中,labelimg下载指令:pip install labelimg
#### 训练过程
创建data.yaml,train.py,使用yolov8n.pt进行训练，结果存放在runs/detect/train中,patience设置为20轮
创建predict.py,使用best.pt进行预测，测试集采用images验证集，结果存放在runs/detect/predict中
#### 训练结果
模型在训练过程中，results.png 显示训练集和验证集的 box_loss、cls_loss、dfl_loss 均呈下降趋势，说明拟合效果较好；精确率（precision）和召回率（recall）在 20 轮后稳定在 0.95 以上，mAP50 接近 1.0，mAP50-95 稳定在 0.7~0.8，表明检测性能优秀，说明模型在高 IoU 阈值下的表现也不错。confusion_matrix.png 显示无漏检（FN=0），但有 23 个背景被误判为 DNB，导致精确率略低于召回率。这意味着：模型几乎不会漏检，但有一部分背景被误判为目标（假阳性较多）结合训练日志可知，模型在第 40 轮提前停止（patience=20），说明已提前收敛
##### 训练结论
模型已经收敛
精确率和召回率都很高，整体性能不错
主要问题是背景误报
#### 误判分析
##### 分析思路
把验证集里所有 FP（把背景当 DNB 的预测）挑出来，算一算它们的框面积占整图面积的比例（area ratio），看是否大多数都是“大框（比例大）”。如果确实是“大框为主”，后续 OCR 不受影响；否则再考虑处理
创建analyze_fp_area.py进行分析
如果大多数 FP 的 area_ratio >= 0.10 基本都是“把整块仪表区域或大面板当成 DNB”，这种情况对后续 OCR（再在框里做二级定位/文字识别）几乎没影响，可以不处理。
如果很多 FP 的 area_ratio < 0.03 说明模型会在画面角落/杂物上点很小的框，这会影响后续流程
##### 分析结果
误检（FP）总数：16
面积占比均值：0.3650，中位数：0.3695
分布：全部都落在 > 0.20 且 ≤ 1.00 档，没有任何 < 2% 的小框
这说明“误判的框”基本都是很大的框（平均覆盖~36%画面），不存在那种只占很小面积的小噪声框。按你之前的标准——如果误判都是“表显区域相对整图比例比较大”，那对后续 OCR 基本不会造成问题
### OCR识别
#### 实施步骤
在目标检测阶段获得了电能表表显区域后，将检测出的区域图像裁剪并送入OCR模块进行数字与文字识别。OCR 选用 PaddleOCR 作为识别工具，原因在于其支持多语言、多场景的轻量化模型，且安装与调用便捷，适合与YOLOv8检测结果进行无缝衔接。
具体流程如下：
将YOLOv8输出的预测框(bbox)结果保存为坐标信息；
使用Python脚本对原始图片进行裁剪，提取出预测框内的电表显示区域；
将裁剪后的图像输入PaddleOCR进行识别，输出文本信息；
将识别结果与对应图片ID一并保存至ocr_result.csv文件中，便于后续分析。
#### 实验环境
Python解释器：Python 3.8
OCR工具：PaddleOCR（pip install paddleocr）
环境：同YOLOv8训练环境，保证依赖一致，便于流水线调用
